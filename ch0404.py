import torch
import numpy as np
import d2lzh_pytorch as d2l
import torch.utils.data

################################################################################################################
# 训练误差和泛化误差的定义
# 训练误差（Training Error）：这是模型在训练集上的平均误差。它衡量了模型对于训练数据的拟合程度。训练误差通常随着模型复杂度的增加而减少。
# 泛化误差（Generalization Error）：这是模型在新、未见过的数据上的预期误差。它衡量了模型在处理新情况时的效果。理想情况下，泛化误差应该与训练误差相近，这表明模型既没有过拟合也没有欠拟合。
################################################################################################################

################################################################################################################
# 训练误差与泛化误差的收敛
# 训练误差通常随着模型训练的进行而减少。然而，如果模型过于复杂或训练时间过长，训练误差可能会过低，导致过拟合，这时泛化误差可能会增加。
# 理想状态是训练误差和泛化误差较低且接近，这意味着模型既没有过度适应训练数据，也能很好地处理新数据。
################################################################################################################

################################################################################################################
# 评估训练误差和泛化误差
# 评估训练误差：通常通过计算模型在训练数据集上的平均误差来评估，如均方误差（MSE）或分类问题中的错误率。
# 评估泛化误差：由于泛化误差涉及未知数据，通常通过在一个独立的测试集上评估模型来估计。测试集应该是从同一分布中抽取但未用于训练的数据。
################################################################################################################

################################################################################################################
# 确定最优模型
# 要确定一个模型是否最优，我们需要关注训练误差和泛化误差之间的平衡：
# 1 交叉验证：使用交叉验证（如K折交叉验证）可以更准确地估计泛化误差。
# 2 早停法：在训练过程中监控验证集的性能。当验证误差开始增加时停止训练，以避免过拟合。
# 3 模型选择：比较不同模型或模型配置的性能。选择在验证集上表现最好的模型。
# 4 正则化技术：应用正则化（如L1或L2）可以帮助防止过拟合，从而改善泛化能力。
# 5 超参数调整：使用网格搜索、随机搜索或贝叶斯优化等技术来寻找最佳超参数，从而找到最优平衡点。
# 通过综合考虑训练误差和泛化误差，可以选择出在新数据上表现良好的模型，从而实现最优的模型选择。
################################################################################################################

n_train, n_test, true_w, true_b = 100, 100, [1.2, -3.4, 5.6], 5
features = torch.randn((n_train + n_test, 1))
# print("features shape: ", features.shape)
# torch.Size([200, 1])
poly_features = torch.cat((features, torch.pow(features, 2), torch.pow(features, 3)), 1)
labels = true_w[0] * poly_features[:, 0] + true_w[1] * poly_features[:, 1] + true_w[2] * poly_features[:, 2] + true_b
# print("labels shape: ", labels.shape)
# torch.Size([200])
labels += torch.tensor(np.random.normal(0, 0.01, size = labels.size()), dtype = torch.float)

# print(features[:2], poly_features[:2], labels[:2])
def semilogy(x_vals, y_vals, x_label, y_label, x2_vals = None, y2_vals = None, legend = None, figsize = (3.5, 2.5)):
    d2l.set_figsize(figsize)
    d2l.plt.xlabel(x_label)
    d2l.plt.ylabel(y_label)
    d2l.plt.semilogy(x_vals, y_vals)
    if x2_vals and y2_vals:
        d2l.plt.semilogy(x2_vals, y2_vals, linestyle = ":")
        d2l.plt.legend(legend)
    d2l.plt.show()

num_epochs, loss = 100, torch.nn.MSELoss()

def fit_and_plot(train_features, test_features, train_labels, test_labels):
    net = torch.nn.Linear(train_features.shape[-1], 1)
    batch_size = min(10, train_features.shape[0])
    dataset = torch.utils.data.TensorDataset(train_features, train_labels)
    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle = True)
    optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)
    train_ls, test_ls = [], []
    for _ in range(num_epochs):
        for X, y in train_iter:
            # 将y调整成n*1的列向量
            l = loss(net(X), y.view(-1, 1))
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
        train_labels = train_labels.view(-1, 1)
        test_labels = test_labels.view(-1, 1)
        train_ls.append(loss(net(train_features), train_labels).item())
        test_ls.append(loss(net(test_features), test_labels).item())
    print('final epoch: train loss', train_ls[-1], 'test loss', test_ls[-1])
    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss', range(1, num_epochs + 1), test_ls, ['train', 'test'])
    print('weight:', net.weight.data, '\nbias:', net.bias.data)

# • 欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。
# • 由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。
# • 验证集可以用于模型选择，但不能过于随意地使用它。
# • 我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本。

################################################################################################################
# 过拟合通常在以下情况下发生：
# 1 训练数据过少：如果训练数据集太小，模型可能无法学习到数据的真实分布，而只是学习到了特定样本的特点。
# 2 模型过于复杂：高度复杂的模型（例如深度学习模型中的大量层和神经元）可能会学习到训练数据中的每个小的波动和噪声。
# 3 训练时间过长：特别是在使用迭代方法（如梯度下降）时，过长的训练时间可能导致模型过度调整以适应训练数据。
# 4 数据特征过多：过多的特征可能包含许多不相关或是冗余的信息，使模型关注于不重要的细节。
# 5 缺乏正则化：没有适当的正则化可能使得模型过度拟合于训练数据。
# 对抗过拟合的方法包括：
# 1 增加数据量：更多的数据可以帮助模型学习到更泛化的特征。
# 2 数据增强：通过旋转、缩放、剪裁等方式人工增加数据的多样性。
# 3 使用更简单的模型：选择参数更少或结构更简单的模型可以减少过拟合的风险。
# 4 正则化技术：如L1和L2正则化，这些技术可以减少模型复杂度。
# 5 早停法（Early Stopping）：在验证集的表现不再提升时停止训练，以避免过度拟合训练数据。
# 6 交叉验证：使用交叉验证可以更好地估计模型在未知数据上的表现。
# 7 降低模型复杂度：减少层数、神经元数量或特征数量。
# 8 使用Dropout：在训练时随机丢弃神经网络中的一部分神经元，以增加模型的泛化能力。
# 9 集成方法：如随机森林、梯度提升树等，可以减少单个模型过拟合的风险。
################################################################################################################

################################################################################################################
# 欠拟合（underfitting）发生在模型无法捕捉到数据中的基本关系时，导致在训练数据和新数据上都表现不佳。
# 欠拟合通常在以下情况下发生：
# 1 模型过于简单：如果模型太简单，它可能无法学习数据中的复杂模式。
# 2 特征处理不当：如果特征选择不当或特征工程未能突出数据的重要属性，模型可能无法有效学习。
# 3 训练不足：如果模型训练不充分（例如迭代次数太少），可能无法收敛到最佳状态。
# 4 数据质量差：噪声过多或数据错误可能会阻碍模型学习。
# 5 过度正则化：过强的正则化可能限制模型的学习能力。
# 对抗欠拟合的方法包括：
# 1 增加模型复杂度：使用更复杂的模型（例如增加层数或神经元数量）可以帮助学习更复杂的数据模式。
# 2 增加训练时间：确保模型有足够的时间来学习和调整。
# 3 特征工程：改进特征选择和处理，确保模型可以使用有意义的信息。
# 4 减少正则化：如果使用了正则化，尝试减轻其强度，以允许模型更好地拟合数据。
# 5 数据质量：改善数据质量，减少噪声和错误。
# 6 更多数据：有时增加数据量可以帮助模型更好地泛化，尽管这在欠拟合的情况下不如过拟合时那么有效。
################################################################################################################


# 正常拟合
fit_and_plot(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:])
# 欠拟合（线性函数拟合）
# fit_and_plot(features[:n_train, :], features[n_train:, :], labels[:n_train], labels[n_train:])
# 过拟合
# fit_and_plot(poly_features[:2, :], poly_features[n_train:, :], labels[:2], labels[n_train:])


################################################################################################################
# 模型复杂度通常是指模型的能力去表示或学习数据中的各种模式和关系。在神经网络的上下文中，模型复杂度确实可以涉及到网络的层数和神经元的数量，但这并非其唯一的指标。模型复杂度的其他方面可能包括：
#   1 层数（Depth）：深度学习模型中的层数。更多的层可以学习更复杂的模式，但也可能导致过拟合。
#   2 神经元数量（Width）：每层中的神经元数量。更多的神经元可以提供更丰富的表示能力，但也增加了模型的参数数量。
#   3 参数总数：模型中的总参数数量，包括权重和偏差。参数越多，模型的容量通常越大。
#   4 连接密度：网络中神经元之间的连接数量。稀疏连接的网络比密集连接的网络具有更低的复杂度。
#   5 激活函数的类型：某些激活函数（如ReLU）可能会使模型学习更复杂的非线性关系。
#   6 网络架构：不同的网络架构（如卷积神经网络、循环神经网络、Transformer）在处理不同类型的数据时表现出不同的复杂度。
#   7 正则化技术：如Dropout或权重衰减，可以影响模型的有效复杂度。
# 因此，尽管层数和神经元数量是评估模型复杂度的重要因素，但还应该考虑到整体架构和其他设计选择。模型复杂度的选择需要根据具体任务、数据量和数据特性来进行平衡，以避免过拟合或欠拟合。
################################################################################################################


################################################################################################################
# K折交叉验证（K-fold cross-validation）是一种用于评估机器学习模型泛化性能的统计方法。它主要用于当数据集不够大时，有效地利用有限的数据进行模型评估和选择。
# K折交叉验证的步骤如下
# 1 分割数据：将整个数据集随机分割为K个大小相等（或近似相等）的子集。
# 2 循环验证：对于每一折（fold）：
#       将其中一折作为验证集，其余的K-1折合并作为训练集。
#       在训练集上训练模型，并在验证集上评估模型性能。
# 3 计算平均性能：重复上述过程K次，每次选择不同的折作为验证集。然后计算这K次评估结果的平均值，得到模型的最终性能指标。
# 优点
#   更准确的模型评估：由于每个数据点都被用作了一次验证集，这提供了对模型性能的更全面和准确的评估。
#   减少偏差：相比于简单的训练集/测试集分割，K折交叉验证减少了模型评估结果依赖于特定训练集或测试集划分的风险。
# 缺点
#   计算开销：特别是对于大型数据集和复杂模型，K折交叉验证需要训练模型K次，这可能导致显著的计算成本。
#   数据分布假设：它假设各折之间是独立且分布一致的。如果数据集本身有偏或者分布不均，则K折交叉验证的结果可能具有误导性。
# 应用
#   K折交叉验证在机器学习中广泛用于模型选择和超参数调整。选择合适的K值是重要的一环。常用的K值有10或5，但最终选择应根据数据集的大小和性质来决定。
#   通过交叉验证，可以更客观地评估不同模型或不同超参数设置的性能，从而选择最佳模型。
################################################################################################################

# =================================问题==================================
# 1 这个多项式回归问题可以准确地解出吗？提示：使用线性代数
# 答： 这个多项式回归问题实际上是一个线性回归问题，因为回归系数是线性的。虽然多项式项增加了模型的非线性，但在回归分析中，只要依赖变量与系数之间的关系是线性的，就可以使用线性回归模型来解决。
#      所以，即使是多项式回归，也可以通过线性代数（具体来说，是最小二乘法）来准确求解。为了准确解出这个问题，我们可以生成数据点，然后使用线性代数方法（如通过构建设计矩阵并应用最小二乘法）来估计系数。
#      在实际应用中，我们通常有一组数据点 (xi, yi)，我们会利用这些数据点来求解系数，使得模型误差（即实际值与预测值之间的差异）最小。

# 2. 绘制训练损失与模型复杂度（多项式的阶数）的关系图。观察到了什么？需要多少阶的多项式才能将训练损失减少到0?
# A:    训练误差随着多项式阶数的增加而降低。在我们的模拟中，当多项式达到10阶时，训练误差降至最低，约为 0.0084（在对数尺度下显示）。这表明一个10阶的多项式模型能够非常好地拟合这些生成的数据点。
#       根据我们的数据生成过程，实际上我们使用的是一个3阶多项式加上一些噪声。由于存在噪声，训练误差不能完全达到0，但可以非常接近0。随着模型的复杂度增加到实际数据生成过程的复杂度，训练误差减少，
#       而超过这个复杂度后，进一步增加模型的复杂度（增加多项式的阶数）将不会显著减少误差，因为噪声限制了误差的下降。在没有过多噪声的情况下，一个与数据生成过程匹配的多项式阶数的模型在训练误差上会接近0。
#       这也符合第二个问题的观点，即在这种情况下（数据生成过程和模型复杂度匹配时）不会出现过拟合。过拟合通常是模型复杂度远超过数据生成过程的复杂度时发生的现象。

# 3. 如果不对多项式特征xi进行标准化(1/i!)，会发生什么事情？能用其他方法解决这个问题吗？
# A:  如果不对多项式特征 xi 进行标准化（即除以 i!），可能会出现几个问题：
#       $ 数值稳定性问题：当 xi 的值较大时，较高阶的多项式项可能会变得非常大。这可能导致计算中的数值不稳定性，尤其是在使用浮点数表示时。
#       $ 梯度问题：在梯度下降或其他基于梯度的优化算法中，不同阶数的特征具有不同的尺度会导致梯度下降过程中步长的选择变得复杂，进而影响收敛速度。
#       $ 权重更新不均衡：在优化过程中，不同特征尺度的差异可能导致某些权重更新过快，而其他权重更新过慢，这会使得模型更难以找到最优解。
#       $ 过拟合风险：由于高阶项数值过大，可能会在模型中赋予这些项过大的权重，增加过拟合的风险。
#     为了解决这些问题，可以采用以下方法：
#       $ 特征标准化：将所有特征缩放到同一尺度，通常是通过减去均值并除以标准差来实现。对于多项式特征，除以 i! 是一种特殊形式的特征缩放。
#       $ 正则化：引入L1或L2正则化项可以惩罚大的权重值，有助于避免过拟合，也可以在一定程度上缓解不同特征尺度造成的问题。
#       $ 改进的优化算法：使用如Adam等自适应学习率的优化算法，可以在一定程度上自动调整不同特征的学习率，减少尺度差异的影响。
#       $ 特征选择：通过特征选择技术减少不必要的高阶项，从而降低模型复杂度。
#       $ 早停法（Early Stopping）：在验证集的误差开始增加时停止训练，以防过拟合，尽管这并不直接解决特征尺度的问题。
#     在实际应用中，特征标准化是机器学习预处理步骤中常见的实践，对于多项式回归，特别是当多项式的阶数很高时，这一步骤尤为重要。

# 4. 泛化误差可能为零吗？
# A:  理论上，泛化误差是模型在所有可能的新样本上的预期误差，这些新样本来自于模型训练时所使用的相同数据分布。泛化误差为零意味着模型能够在任何新样本上都做出完美预测，这在实际中是非常罕见的，尤其是在有限的数据和噪声存在的情况下。
#       以下是几个为什么泛化误差不太可能为零的原因：
#           数据噪声：现实世界的数据通常包含噪声，即使是最佳模型也无法预测这种随机噪声。
#           模型假设：所有模型都是基于某些假设构建的，这些假设可能与实际数据的真实生成过程不完全匹配。
#           特征限制：模型可能无法访问决定目标变量的所有相关特征，因为有些特征可能是未知的或无法测量的。
#           数据样本限制：即使在没有噪声的情况下，有限的数据样本可能无法充分代表整个数据分布的复杂性。
#           模型选择：在实际应用中，可能没有一个模型能够完美地捕捉数据的所有复杂性和变化。
#     在理想化的情况下，如果数据没有噪声，并且模型假设与数据的真实生成过程完全一致，那么泛化误差有可能为零。例如，在一些受控的实验环境中，或者某些简单问题上，完美的泛化是可能的。但在大多数现实世界的情况下，期望泛化误差为零是不现实的。相反，目标通常是最小化泛化误差，使模型在新数据上的表现尽可能好。
